= Kubernetes - Enforcing Network Security Policies with Weave Net
:toc:

https://www.weave.works/docs/net/latest/kubernetes/kube-addon/[Weave Net] provides a program called the Weave NPC (network policy controller). The NPC runs once on every host, and routes the traffic according to the rules set up in the YAML file. Weave Net does this by talking to IPtables which is a feature of Linux.

At the top level forward chain, a rule is injected that checks whether a WEAVE-NPC policy applies, and if it doesn’t, then the packet is dropped. If is does, and if there is an established connection, then the packet is accepted. Only packets with newly opened connections are checked. Therefore, if the packet is already on an established connection, it is accepted, and the other chains are checked. IPtables rules are updated when the policy’s ‘ipsets’ are changed on every coming and going pod. Weave begins with the source address on the network, which goes over a linux bridge. In the course of traversing that bridge, the connection is checked against the IPtables rules.

This exercise will walk you through configuring Weave Net and applying a Network Policy.

== Prerequisites

This chapter uses a cluster with 3 master nodes and 5 worker nodes as described here: link:../../cluster-install#multi-master-multi-node-multi-az-gossip-based-cluster[multi-master, multi-node gossip based cluster], except we ask kops to use Weave Net as shown below:

  kops create cluster \
    --name example2.cluster.k8s.local \
    --master-count 3 \
    --node-count 5 \
    --zones ${AWS_AVAILABILITY_ZONES} \
    --networking weave \
    --yes

It uses `--networking weave` which tells the cluster to use Weave Net instead of the default networking provided by kubenet. Note, the name here is `example2.cluster.k8s.local` instead of the usual `example.cluster.k8s.local` name. This is just to make sure, in case, the two clusters can coexist.

To check the network configuration is using Weave Net, view the cluster configuration using the following command:

  kops edit cluster example2.cluster.k8s.local

This will show the following fragment under `.spec`:

  networking:
    weave: {}

Quit the edit without making any changes; this step was just to check.

This chapter also uses some files from the repo; please `cd` into `network-policies/weavenet` to use them.

=== Update Weave Net to 2.1.3 in kops 1.7.x
kops 1.7.x comes with Weave Net 2.0.5 out-of-the-box which does not support the latest network-policy updates for kubernetes 1.7.
In order to make this work, we need to update Weave Net via:

```
$ kubectl apply -f templates/weavenet-update.yaml
clusterrole "weave-net" configured
serviceaccount "weave-net" unchanged
clusterrolebinding "weave-net" configured
role "weave-net" created
rolebinding "weave-net" created
daemonset "weave-net" configured
```

After this, wait for the Weave Net pods to be updated via:
```
$ kubectl rollout status ds/weave-net -n kube-system
Waiting for rollout to finish: 0 out of 8 new pods have been updated...
Waiting for rollout to finish: 1 out of 8 new pods have been updated...
[...]
Waiting for rollout to finish: 7 of 8 updated pods are available...
daemon set "weave-net" successfully rolled out
```

== Enforcing network isolation

Let's configure Kubernetes Network Policies.

We will create a namespace, deploy some test pods into it, and see the before and after effects of configuring a Network Policy, which will be enforced by Weave Net.

=== Precheck

. Create a namespace:

  $ kubectl create ns ns-1
  namespace "ns-1" created

. Deploy a container into namespace `ns-1` that will expose an http endpoint, and log all requests it receives. First, create a Deployment, ReplicaSet and Pod using the command:

  $ kubectl run --namespace=ns-1 http-echo --image=solsson/http-echo --env="PORT=80" --port=80
  deployment "http-echo" created

. Label the pod (we will use labels as part of defining network policies):

  $ kubectl label po --selector=run=http-echo --namespace=ns-1 app=http-echo
  pod "http-echo-1790350443-z2v7n" labeled

. Create a Service to expose the pod:

  $ kubectl expose --namespace=ns-1 deployment http-echo --port=80
  service "http-echo" exposed
+
Monitor the logs of the deployed container by querying the name of the pod defined with the label `run=http-echo`, then passing it to the `kubectl logs` command:
+
```
kubectl get po \
  --selector=run=http-echo \
  --namespace=ns-1 \
  -o jsonpath='{.items[*].metadata.name}' | \
  xargs kubectl logs -f --namespace=ns-1
```
+
This command will sit silently until `http-echo` logs a request.
+
Let's say this is `shell 1`.
+
. In another shell, say `shell 2`, deploy a second container:

  $ kubectl run \
    --namespace=ns-1 \
    -i --tty \
    busybox \
    --image=busybox \
    --restart=Never \
    -- sh
  If you don't see a command prompt, try pressing enter.
  / #
+
. We will now attempt to call the `http-echo` pod from our `busybox` pod by performing an HTTP POST .  As we have no network policies in place, we should see the following command return successfully with a 200 response, along with a log message being output in the `http-echo` shell window:
+
```
/ # wget -S http://http-echo.ns-1.svc.cluster.local/test --post-data '{"message":"hello"}' -O test
Connecting to http-echo.ns-1.svc.cluster.local (100.71.77.153:80)
  HTTP/1.1 200 OK
  X-Powered-By: Express
  Content-Type: application/json; charset=utf-8
  Content-Length: 533
  ETag: W/"215-KyoPN1JoGjQlzW9TxpIay22VPF8"
  Date: Thu, 26 Oct 2017 00:53:21 GMT
  Connection: close

test                 100% |*************************************************************************************************|   533   0:00:00 ETA
```
HTTP POST request succeeds.

=== Create default network policy

Let's now create a Network Policy, but we will not configure any rules which by default will deny all traffic within the namespace.  Leaving the 2 shells open from the previous steps, run the following in another shell, say `shell 3`:

  $ kubectl create -f templates/deny-all-by-default-network-policy.yaml --namespace=ns-1
  networkpolicy "deny-all-by-default" created

When running the following command again in shell 2, we should see it eventually timeout and fail (note that rather than waiting for it to time out, you can press `Ctrl` + `C` to quit after about 10 seconds once satisfied that no response will be returned):

```
/ # wget -S http://http-echo.ns-1.svc.cluster.local/test --post-data '{"message":"hello"}' -O test
Connecting to http-echo.ns-1.svc.cluster.local (100.64.161.56:80)
wget: can't connect to remote host (100.64.61.223): Connection timed out
```

=== Create network policy with a rule

We will now delete the NetworkPolicy that we just created, and create a new NetworkPolicy with a rule defined.  If you `cat templates/allow-network-policy.yaml` you will see the following rule defined:

  spec:
    podSelector:
      matchLabels:
        app: http-echo
    ingress:
      - from:
        - podSelector:
            matchLabels:
              app: busybox

The rule above is stating that for every pod that has the label `app: http-echo` defined, allow access to it from pods that have the label `app: busybox` defined.

Run the following in `shell 3` to remove the deny all by default rule, and replace with the above allow rule:

  $ kubectl delete netpol deny-all-by-default --namespace=ns-1
  networkpolicy "deny-all-by-default" deleted
  $ kubectl create -f templates/allow-network-policy.yaml --namespace=ns-1
  networkpolicy "allow" created

If we repeat the following command in `shell 2`, the call should still timeout and fail (again, you can press CTRL-C to quit after 10 seconds rather than waiting for the full timeout to occur):

```
/ # wget -S http://http-echo.ns-1.svc.cluster.local/test --post-data '{"message":"hello"}' -O test
Connecting to http-echo.ns-1.svc.cluster.local (100.64.161.56:80)
wget: can't connect to remote host (100.64.61.223): Connection timed out
```

Why is this still failing even after creating a rule?  It is failing because we configured the rule so that only pods with the label `app: busybox` are authorized to call pods with the label `app: http-echo`.  Let's go ahead and label our `busybox` pod on `shell 3`:

  / # kubectl label po --selector=run=busybox --namespace=ns-1 app=busybox
  pod "busybox" labeled

Repeating the test in `shell 2` again should now be successful:

```
/ # wget -S http://http-echo.ns-1.svc.cluster.local/test --post-data '{"message":"hello"}' -O test
Connecting to http-echo.ns-1.svc.cluster.local (100.64.161.56:80)
  HTTP/1.1 200 OK
  X-Powered-By: Express
  Content-Type: application/json; charset=utf-8
  Content-Length: 536
  ETag: W/"218-xgvU8WZSN+2SEyOX6Q2R/AhLuRM"
  Date: Thu, 26 Oct 2017 02:15:32 GMT
  Connection: close

test                100% |*************************************************************************************************|   534   0:00:00 ETA
```

== Teardown

Remove all the resources and the namespace using the command:

  \ # kubectl delete ns ns-1
  namespace "ns-1" deleted

== Advanced Topics

