:toc:

= Kubernetes Developer Concepts

Kubernetes has a number of abstractions that map to API objects. These Kubernetes API Objects can be used to describe your cluster's desired state which will include info such as applications and workloads running, replicas, container images, networking resources and more. This section explains the key concepts relevant from an application developer perspecitve.

== Deployments

A "`desired state`", such as 4 replicas of a pod, can be described in a Deployment object. The Deployment controller in Kubernetes cluster then ensures the desired and the actual state are matching. Deployment ensures the recreation of a pod when the worker node fails or reboots. It also allows both up- and down-scaling the number of replicas. 

If a pod dies, then a new pod is started to ensure the desired vs actual matches.

=== Create a Deployment

The folowing example will create a Deployment with 3 replicas of NGINX base image. Let's begin with the template:

	apiVersion: extensions/v1beta1
	kind: Deployment # kubernetes object type
	metadata:
	  name: nginx-deployment # deployment name
	spec:
	  replicas: 3 # number of replicas
	  template:
	    metadata:
	      labels:
	        app: nginx # pod labels
	    spec:
	      containers:
	      - name: nginx # container name
	        image: nginx:1.12.1 # nginx image
	        imagePullPolicy: IfNotPresent # if exists, will not pull new image
	        ports: # container and host port assignments
	        - containerPort: 80
	        - containerPort: 443

This deployment will create 3 instances of NGINX image.

Run the following command to create Deployment:

	kubectl create -f templates/deployment.yaml --record

The `--record` flag will track changes made through each revision.

To monitor deployment rollout status:

	kubectl rollout status deployment/nginx-deployment

A Deployment creates a ReplicaSet to manage the number of replicas. Let's take a look at existing deployments and replica set.

```
$ kubectl get deployments
NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3         3         3            3           25s
$ kubectl get replicaset
NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-3081318877   3         3         3         31s
$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-3081318877-1xt4t   1/1       Running   0          58s
nginx-deployment-3081318877-8212t   1/1       Running   0          58s
nginx-deployment-3081318877-dxhxw   1/1       Running   0          58s
```

=== Scaling a Deployment

Number of replicas for a Deployment can be scaled using the following command:

    kubectl scale --replicas=5 deployment/nginx-deployment

Verify deployment and pods:

```
$ kubectl get deployments
NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   5         5         5            5           35s
$ kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-3441592026-d8z6m   1/1       Running   0          1m
nginx-deployment-3441592026-f85rb   1/1       Running   0          1m
nginx-deployment-3441592026-r4p85   1/1       Running   0          1m
nginx-deployment-3441592026-tj0xh   1/1       Running   0          1m
nginx-deployment-3441592026-w5m40   1/1       Running   0          1m
```

=== Update a Deployment

A more general update to Deployment can be made by making edits to the spec template. In this example, let's change to the latest nginx image.

First, type the following to open up a text editor:

	kubectl edit deployment/nginx-deployment

Next, change the image from `nginx:1.12.1` to `nginx:latest`.

This should perform a rolling update of the deployment. To track the deployment details such as revision, image version, and ports - type in the following:

	kubectl describe deployments

The output should look similar the following:

```
$ kubectl describe deployments
Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sun, 22 Oct 2017 22:18:11 -0400
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=2
                        kubernetes.io/change-cause=kubectl edit deployment/nginx-deployment
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  1 max unavailable, 1 max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:latest
    Ports:        80/TCP, 443/TCP
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   nginx-deployment-886641336 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-3441592026 to 3
  Normal  ScalingReplicaSet  1m    deployment-controller  Scaled up replica set nginx-deployment-3441592026 to 7
  Normal  ScalingReplicaSet  54s   deployment-controller  Scaled down replica set nginx-deployment-3441592026 to 3
  Normal  ScalingReplicaSet  10s   deployment-controller  Scaled up replica set nginx-deployment-886641336 to 1
  Normal  ScalingReplicaSet  10s   deployment-controller  Scaled down replica set nginx-deployment-3441592026 to 2
  Normal  ScalingReplicaSet  9s    deployment-controller  Scaled up replica set nginx-deployment-886641336 to 2
  Normal  ScalingReplicaSet  8s    deployment-controller  Scaled down replica set nginx-deployment-3441592026 to 1
  Normal  ScalingReplicaSet  8s    deployment-controller  Scaled up replica set nginx-deployment-886641336 to 3
  Normal  ScalingReplicaSet  8s    deployment-controller  Scaled down replica set nginx-deployment-3441592026 to 0
```

=== Rollback a Deployment

To rollback to a previous version, first check the revision history:

	kubectl rollout history deployment/nginx-deployment

If you only want to rollback to the previous revision, enter the following command:

	kubectl rollout undo deployment/nginx-deployment

In our case, the deployment will rollback to use the `nginx:1.12.1` image.

If rolling back to a specific revision then enter:

	kubectl rollout undo deployment/nginx-deployment --to-revision=1

=== Delete a Deployment

Run the following command to delete deployment:

	kubectl delete -f templates/deployment.yaml

== Replica Sets

A RepllicaSet specifies a number of pod replicas that can be run at any given time. The Deployment manages the ReplicaSets and provides updates to those pods. ReplicaSets can be used in lieu of Deployments if you require custom orchestration or do not need updates.

For replica set, matching of pods is done according to a set of values. The supported operators are `in`, `notin` and `exists` (only for the key). For example, replication controller can select pods such as "`environment = dev`". Replica set can select pods such as "`environment in ["dev", "test"]`".

=== Create a ReplicaSet

The folowing will be an example ReplicaSet with an NGINX base image. Let's begin with the template:

	apiVersion: extensions/v1beta1
	kind: ReplicaSet
	metadata:
	  name: nginx-replicaset
	spec:
	  replicas: 3
	  template:
	    metadata:
	      labels:
	        name: nginx-replica
	    spec:
	      containers:
	      - name: nginx-replica
	        image: nginx:1.12.1
	        imagePullPolicy: IfNotPresent
	        ports:
	        - containerPort: 80
	        - containerPort: 443

Run the following command to create the ReplicaSet and pods:

	kubectl create -f templates/replicaset.yaml --record

The `--record` flag will track changes made through each revision.

To track the ReplicaSet details type in the following:

	kubectl describe rs/nginx-replicaset

The output should look similar the following:

```
$ kubectl create -f templates/replicaset.yaml --record
replicaset "nginx-replicaset" created
developer-concepts $ kubectl describe rs/nginx-replicaset
Name:         nginx-replicaset
Namespace:    default
Selector:     name=nginx-replica
Labels:       name=nginx-replica
Annotations:  kubernetes.io/change-cause=kubectl create --filename=templates/replicaset.yaml --record=true
Replicas:     3 current / 3 desired
Pods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  name=nginx-replica
  Containers:
   nginx-replica:
    Image:        nginx:1.12.1
    Ports:        80/TCP, 443/TCP
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From                   Message
  ----    ------            ----  ----                   -------
  Normal  SuccessfulCreate  10s   replicaset-controller  Created pod: nginx-replicaset-tzvz3
  Normal  SuccessfulCreate  10s   replicaset-controller  Created pod: nginx-replicaset-lhmgq
  Normal  SuccessfulCreate  10s   replicaset-controller  Created pod: nginx-replicaset-p5l6x
```

=== Scale a Replica Set

Number of replicas in a Replica Set can be scaled up using the following command:

```
$ kubectl get rs
NAME               DESIRED   CURRENT   READY     AGE
nginx-replicaset   3         3         3         1m
developer-concepts $ kubectl scale --replicas=5 rs/nginx-replicaset
replicaset "nginx-replicaset" scaled
developer-concepts $ kubectl get rs
NAME               DESIRED   CURRENT   READY     AGE
nginx-replicaset   5         5         5         2m
developer-concepts $ kubectl get pods
NAME                     READY     STATUS    RESTARTS   AGE
nginx-replicaset-gmkj3   1/1       Running   0          18s
nginx-replicaset-k77kg   1/1       Running   0          18s
nginx-replicaset-lhmgq   1/1       Running   0          2m
nginx-replicaset-p5l6x   1/1       Running   0          2m
nginx-replicaset-tzvz3   1/1       Running   0          2m
```    

=== Delete a Replica Set

A Replica Set can be deleted using the following command:

```
$ kubectl delete rs/nginx-replicaset
replicaset "nginx-replicaset" deleted
```

== Services

A pod is ephemeral. Each pod is assigned a unique IP address. If a pod that belongs to a replication controller dies, then it is recreated and may be given a different IP address. Further, aAdditional pods may be created using Deployment or Replica Set. This makes it difficult for an application server, such as WildFly, to access a database, such as MySQL, using its IP address.

A Service is an abstraction that defines a logical set of pods and a policy by which to access them. The IP address assigned to a service does not change over time, and thus can be relied upon by other pods. Typically, the pods belonging to a service are defined by a label selector. This is similar mechanism to how pods belong to a replica set.

This abstraction of selecting pods using labels enables a loose coupling. The number of pods in the deployment may scale up or down but the application server can continue to access the database using the service.

A Kubernetes service defines a logical set of pods and enables them to be access through micro-services. 

=== Create a Service

In the following example, we create a service labeled demo-service:

	apiVersion: v1
	kind: Service
	metadata:
	  name: demo-service
	spec:
	  selector:
	    app: demo-app
	  ports:
	  - name: http
	    protocol: TCP
	    port: 80
	    targetPort: 8080

The service itself is assigned an IP address used by service proxies. It also defines the incoming ports 80 and 443 to target ports 3030 and 3031. 

* Note that Kubernetes supports both TCP and UDP protocols.

=== Service Discovery

For each Pod that is created, a set of environmental variables are created for each active service. Alternatively, a DNS server can be used to watch the Kubernetes API for new services and creates DNS records for each.

If you would like to expose a service to an external IP, ServiceTypes are used to determine the type of service. Those ServiceTypes are:

	`ClusterIP`: Service exposed on a internal cluster IP.
	`NodePort`: Service exposed on each Node's IP at a defined port.
	`LoadBalancer`: Service exposed externally using a cloud based load balancer. 
	`ExternalName`: Service is attached to the externalName field. It is mapped to a CNAME with the value.

Below we will provision a load balancer and expose your services, add a `type` field of LoadBalancer. 

First deploy an app. In this example, we will create an echo app that responds with http headers from an Elastic Load Balancer:

	apiVersion: extensions/v1beta1
	kind: Deployment
	metadata:
	  name: demo-deployment 
	spec:
	  replicas: 3 
	  template:
	    metadata:
	      labels:
	        app: demo-app 
	    spec:
	      containers:
	      - name: echoheaders 
	        image: gcr.io/google_containers/echoserver:1.4
	        imagePullPolicy: IfNotPresent 
	        ports: 
	        - containerPort: 8080
	          hostPort: 8080  

Type the following to create the deployment:

	kubectl create -f templates/echo.yaml --record

Use the `kubectl describe deployment` command to confirm demo-app has been deployed:

	$ kubectl describe deployment
	Name:                   demo-deployment
	Namespace:              default
	CreationTimestamp:      Mon, 02 Oct 2017 13:13:12 -0700
	Labels:                 app=demo-app
	Annotations:            deployment.kubernetes.io/revision=1
	                        kubernetes.io/change-cause=kubectl create --filename=https://github.com/arun-gupta/kubernetes-aws-workshop/blob/master/templates/echo.yaml --record=true
	Selector:               app=demo-app
	Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
	StrategyType:           RollingUpdate
	MinReadySeconds:        0
	RollingUpdateStrategy:  1 max unavailable, 1 max surge
	Pod Template:
	  Labels:       app=demo-app
	  Containers:
	   echoheaders:
	    Image:              gcr.io/google_containers/echoserver:1.4
	    Port:               8080/TCP
	    Environment:        <none>
	    Mounts:             <none>
	  Volumes:              <none>
	Conditions:
	  Type          Status  Reason
	  ----          ------  ------
	  Available     True    MinimumReplicasAvailable
	OldReplicaSets: <none>
	NewReplicaSet:  demo-deployment-706676907 (3/3 replicas created)
	Events:
	  FirstSeen     LastSeen        Count   From                    SubObjectPath   Type            Reason                  Message
	  ---------     --------        -----   ----                    -------------   --------        ------                  -------
	  29s           29s             1       deployment-controller                   Normal          ScalingReplicaSet       Scaled up replica set demo-deployment-706676907 to 3

This template will expose "demo-app" to the internet by creating an outward facing elastic load balancer (ELB):

	apiVersion: v1
	kind: Service
	metadata:
	  name: demo-service
	spec:
	  selector:
	    app: demo-app
	  ports:
	  - name: http
	    protocol: TCP
	    port: 80
	    targetPort: 8080
	  type: LoadBalancer

Run the following command to create the service:

	kubectl create -f templates/service.yaml --record

After describing, you should get something like the following:

	$ kubectl describe services
	Name:                   demo-service
	Namespace:              default
	Labels:                 <none>
	Annotations:            kubernetes.io/change-cause=kubectl create --filename=https://github.com/arun-gupta/kubernetes-aws-workshop/blob/master/templates/service.yaml --record=true
	Selector:               app=demo-app
	Type:                   LoadBalancer
	IP:                     1.1.1.131
	LoadBalancer Ingress:   {random-sequence}.us-west-2.elb.amazonaws.com
	Port:                   http    80/TCP
	NodePort:               http    31959/TCP
	Endpoints:              1.1.1.65:8080,1.1.1.131:8080,1.1.1.194:8080
	Session Affinity:       None
	Events:
	  FirstSeen     LastSeen        Count   From                    SubObjectPath   Type            Reason                  Message
	  ---------     --------        -----   ----                    -------------   --------        ------                  -------
	  5s            5s              1       service-controller                      Normal          CreatingLoadBalancer    Creating load balancer
	  2s            2s              1       service-controller                      Normal          CreatedLoadBalancer     Created load balancer


	Name:                   kubernetes
	Namespace:              default
	Labels:                 component=apiserver
	                        provider=kubernetes
	Annotations:            <none>
	Selector:               <none>
	Type:                   ClusterIP
	IP:                     10.10.0.1
	Port:                   https   443/TCP
	Endpoints:              1.2.3.29:443
	Session Affinity:       ClientIP
	Events:                 <none>

Wait for 3 minutes for the load balancer to be ready to be used. If you go to the LoadBalancer Ingress in your browser, you should hit a webpage containing the echo response.

=== Delete a Service


== Daemon Sets

DeamonSets allow the cluster of nodes to run a specified pod. As nodes are added, pods are added. As nodes are removed, pods are removed through garbage collection.  

=== Create a DaemonSet

The folowing will be an example DaemonSet that runs a logstash image. Let's begin with the template:

	apiVersion: extensions/v1beta1
	kind: DaemonSet
	metadata:
	  name: logstash-daemonset
	  labels:
	    app: logstash
	spec:
	  template:
	    metadata:
	      labels:
	        app: logstash
	    spec:
	      containers:
	      - name: logstash
	        image: logstash:5.5.2
	        imagePullPolicy: IfNotPresent # if exists, will not pull new image
	        resources:
	          limits:
	            memory: 50Mi
	          requests:
	            cpu: 50m
	            memory: 50Mi
	        volumeMounts:
	        - name: varlog
	          mountPath: /var/log
	        - name: varlibdockercontainers
	          mountPath: /var/lib/docker/containers
	          readOnly: true
	      volumes:
	      - name: varlog
	        hostPath:
	          path: /var/log
	      - name: varlibdockercontainers
	        hostPath:
	          path: /var/lib/docker/containers

Run the following command to create the ReplicaSet and pods:

	kubectl create -f templates/daemonset.yaml --record

The `--record` flag will track changes made through each revision.

To track the ReplicaSet details type in the following:

	kubectl describe ds/logstash-daemonset

The output should look similar the following:

	$ kubectl describe ds
	Name:           logstash-daemonset
	Selector:       app=logstash
	Node-Selector:  <none>
	Labels:         app=logstash
	Annotations:    kubernetes.io/change-cause=kubectl create --filename=daemonset.yaml --record=true
	Desired Number of Nodes Scheduled: 3
	Current Number of Nodes Scheduled: 3
	Number of Nodes Scheduled with Up-to-date Pods: 3
	Number of Nodes Scheduled with Available Pods: 3
	Number of Nodes Misscheduled: 0
	Pods Status:    3 Running / 0 Waiting / 0 Succeeded / 0 Failed
	Pod Template:
	  Labels:       app=logstash
	  Containers:
	   logstash:
	    Image:      logstash:5.5.2
	    Port:       <none>
	    Limits:
	      memory:   50Mi
	    Requests:
	      cpu:              50m
	      memory:           50Mi
	    Environment:        <none>
	    Mounts:
	      /var/lib/docker/containers from varlibdockercontainers (ro)
	      /var/log from varlog (rw)
	  Volumes:
	   varlog:
	    Type:       HostPath (bare host directory volume)
	    Path:       /var/log
	   varlibdockercontainers:
	    Type:       HostPath (bare host directory volume)
	    Path:       /var/lib/docker/containers
	Events:
	  FirstSeen     LastSeen        Count   From            SubObjectPath   Type            Reason                  Message
	  ---------     --------        -----   ----            -------------   --------        ------                  -------
	  6s            6s              1       daemon-set                      Normal          SuccessfulCreate        Created pod: logstash-daemonset-zjw24
	  6s            6s              1       daemon-set                      Normal          SuccessfulCreate        Created pod: logstash-daemonset-b0w72
	  6s            6s              1       daemon-set                      Normal          SuccessfulCreate        Created pod: logstash-daemonset-hb365

=== Limit DaemonSets to specific nodes

Verify that the logstash pod was successfully deployed to the cluster nodes:

	kubectl get pods -o wide

Output should mirror the following:

	$ kubectl get pods -o wide
	NAME                       READY     STATUS    RESTARTS   AGE       IP           NODE
	logstash-daemonset-b0w72   1/1       Running   1          1m        100.96.2.9   ip-172-20-76-225.us-west-2.compute.internal
	logstash-daemonset-hb365   1/1       Running   0          1m        100.96.1.9   ip-172-20-38-189.us-west-2.compute.internal
	logstash-daemonset-zjw24   1/1       Running   2          1m        100.96.3.9   ip-172-20-121-97.us-west-2.compute.internal

Rename one of the node labels as follows:

	kubectl label node ip-172-20-38-189.us-west-2.compute.internal app=logstash-node

Next, edit the DaemonSet template to include a nodeSelector that matches the changed label:

	................
	spec:
	  nodeSelector:
	    app: logstash-node
      containers:
      - name: logstash
        image: logstash:5.5.2
    ................

After the update is performed, we have now configured logstash to run off a specific node:

	$ kubectl get pods
	NAME                       READY     STATUS        RESTARTS   AGE
	logstash-daemonset-hb365   1/1       Running       5          26m
	logstash-daemonset-pzvkw   1/1       Terminating   0          1m
	logstash-daemonset-t9f0n   1/1       Terminating   0          1m

=== Delete a DaemonSet

