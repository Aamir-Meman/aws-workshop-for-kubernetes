= Add Ingress Controllers to Kubernetes cluster
:toc:

This chapter explains how to apply both Nginx and AWS ALB Ingress Controllers to a Kubernetes cluster.
These controllers allow you to set rules that control the routing of external traffic to the services in your Kubernetes cluster.
The role of the Ingress controller is to watch the Kubernetes API server for ingress events, and to action those events.
For example, creating an Ingress resource is an event. The Ingress controller will act on the event by creating the
appropriate Ingress resource; in the case of this example, this could be an Nginx or an AWS ALB resource.

Kubernetes Ingress has two parts:
 * Ingress resource: the Ingress definition, defined in a YAML file
 * Ingress controller: deployed on the Kubernetes master, the controller implements the Ingress in your cluster.
There is no default Ingress controller provided in Kubernetes. It may be provided by your platform, or you must install one.
Since an Ingress controller is not provided on AWS by default, we will install one.

== Prerequisites

This chapter uses a cluster with 3 master nodes and 5 worker nodes as described here: link:../cluster-install#multi-master-multi-node-multi-az-gossip-based-cluster[multi-master, multi-node gossip based cluster].

== Nginx Ingress Controller

Perform the following steps to install an Nginx ingress controller for your Kubernetes cluster. It will be exposed using the AWS Elastic Load Balancer.

First, apply the initial setup commands:

	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml | kubectl apply -f -
	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml | kubectl apply -f -
	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml | kubectl apply -f -
	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/tcp-services-configmap.yaml | kubectl apply -f -
	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/udp-services-configmap.yaml | kubectl apply -f -

RBAC roles, or Role Based Access Control, are methods for controlling access to resources based on roles and permissions of individual users. RBAC must be enabled on the api server with the flag, `--authorization-mode=RBAC`. A `Role` can be used to restrict access to a single namespace. Alternatively, a `ClusterRole` can apply access permissions to a particular namespace or across all namespaces. In addition, `RoleBinding` binds the permissions granted by a role to a single user or set of users. `ClusterRoleBinding` can grant these permissions cluster wide and across all namespaces.

To configure the Nginx Ingress Controller with RBAC roles use the following command:

	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/without-rbac.yaml | kubectl apply -f -

To configure with RBAC:

	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml | kubectl apply -f -
	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/with-rbac.yaml | kubectl apply -f 

The AWS ELB allows you to apply both L4 and L7 network protocols for ingress behind `Type=LoadBalancer`. Layer 4 uses TCP as the listener protocol for ports 80 and 443. Layer 7 uses HTTP for port 80 and terminates TLS at the ELB.

To configure Layer 4:

	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/aws/service-l4.yaml
	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/aws/patch-configmap-l4.yaml

To configure Layer 7:

	curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/aws/service-l7.yaml > service-l7.yaml

Edit the the line of the file service-l7.yaml to replace the dummy id with a valid one in the form "arn:aws:acm:us-west-2:XXXXXXXX:certificate/XXXXXX-XXXXXXX-XXXXXXX-XXXXXXXX"
	
	kubectl apply -f service-l7.yaml
	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/aws/patch-configmap-l7.yaml

If RBAC is enabled, apply the following:

	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/patch-service-with-rbac.yaml

If not, apply this command:

	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/patch-service-without-rbac.yaml

== ALB Ingress Controller

CoreOS has developed an Ingress controller that uses AWS Application Load Balancer (ALB) to route traffic to Kubernetes services.
We'll deploy this Ingress controller and use it to route traffic to our Pods.

=== IAM role

You should already have an IAM role assigned to your Kubernetes worker nodes. The role ARN will be similar to
`arn:aws:iam::123456789012:role/nodes.cluster.k8s.local`. Check the role in the IAM Console and make sure it
contains the following for the nodes.cluster.k8s.local inline policy:

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:*"
            ],
            "Resource": [
                "*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticloadbalancing:*"
            ],
            "Resource": "*"
        },
        .
        .
```

=== Ingress controller

As mentioned earlier, deploying an Ingress resource has no effect unless there is an Ingress controller that implements
 the resource. This involves two steps:

 * deploying the `default-http-backend` resource that all Ingress controllers depend upon
 * deploying the Ingress controller itself

First, deploy the `default-http-backend` resource:

    $ kubectl create -f https://raw.githubusercontent.com/coreos/alb-ingress-controller/master/examples/default-backend.yaml

Then deploy the Ingress controller:

    $ kubectl create -f templates/alb-ingress-controller.yaml

=== Sample application

We'll deploy a sample application that we'll expose via an Ingress. We will use the same greeter application as used
in the microservices section, with one small change: we'll expose the webapp service using a NodePort instead of a LoadBalancer.
The difference is that NodePort maps the container port to a port on the node hosting the container. The same port
will be used on each node. LoadBalancer, on the other hand, will create an AWS ELB that balances traffic across the
pods running on the worker nodes. In this example, we'll use an Ingress to create an ALB to balance traffic across the
pods running on the worker nodes.

. Deploy the application:

  $ kubectl create -f templates/app.yml

. Get the list of services:

  $ kubectl get svc
    NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
    greeter-service   ClusterIP   100.71.100.49    <none>        8080/TCP       57m
    kubernetes        ClusterIP   100.64.0.1       <none>        443/TCP        27d
    name-service      ClusterIP   100.71.205.66    <none>        8080/TCP       57m
    webapp-service    NodePort    100.70.135.114   <none>        80:32202/TCP   57m

=== Ingress resource

Deploy the Ingress resource. This will create an AWS ALB and route traffic to the pods in the service using ALB
target groups:

    $ kubectl create -f templates/alb-ingress-resource.yaml

It will take a couple of minutes to create the ALB associated with your Ingress. Check the status as follows:

    $ kubectl describe ing webapp-alb-ingress

```
Name:             webapp-alb-ingress
Namespace:        default
Address:          clusterk8sl-default-webapp-9895-1236164836.us-east-1.elb.amazonaws.com
Default backend:  default-http-backend:80 (100.96.7.26:8080)
Rules:
  Host  Path  Backends
  ----  ----  --------
  *
        /   webapp-service:80 (<none>)
Annotations:
Events:
  Type    Reason  Age               From                Message
  ----    ------  ----              ----                -------
  Normal  CREATE  32m               ingress-controller  clusterk8sl-default-webapp-9895 created
  Normal  CREATE  32m               ingress-controller  clusterk8sl-32202-HTTP-5a4bb0d target group created
  Normal  CREATE  32m               ingress-controller  80 listener created
  Normal  CREATE  32m               ingress-controller  1 rule created
  Normal  CREATE  3m (x3 over 32m)  ingress-controller  Ingress default/webapp-alb-ingress
  Normal  UPDATE  3m (x6 over 32m)  ingress-controller  Ingress default/webapp-alb-ingress
```

This shows your Ingress is listening on port 80. Now check the status of your service:

    $ kubectl get svc webapp-service
```
NAME             TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
webapp-service   NodePort   100.70.135.114   <none>        80:32202/TCP   1h
```

This shows your service is listening on port 32202 (your port may differ). I expect an ALB to be created with a listener
on port 80, and a target group routing traffic to port 32202 on each of my nodes. Port 32202 is the NodePort that maps
to my container port.

Use the EC2 Console to check the status of your ALB. Check the Target Groups and see if they are routing traffic to
port 32202 (this should be evident in the Description and Targets tab, i.e. the health checks should also route to
this port). Check the Load Balancer listener - it should be listening on port 80.

Once the ALB has a status of 'active' in the EC2 Console, you can curl your Ingress endpoint using the Address
of the Ingress resource:

    $ curl clusterk8sl-default-webapp-9895-1236164836.us-east-1.elb.amazonaws.com
    Hello Arunc

=== Cleanup

    $ kubectl delete -f templates/alb-ingress-resource.yaml
    $ kubectl delete -f templates/app.yml
    $ kubectl delete -f templates/alb-ingress-controller.yaml
    $ kubectl delete -f https://raw.githubusercontent.com/coreos/alb-ingress-controller/master/examples/default-backend.yaml

Check in the EC2 console to ensure your ALB has been deleted.