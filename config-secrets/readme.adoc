:icons:
:linkcss:
:imagesdir: ../images

= Kubernetes ConfigMap and Secrets
:toc:

Kubernetes has resource types that allows to decouple application code from configuration. It makes the applications to be more portable. This chapter will cover how ConfigMap and Secrets can be used to do that.

. ConfigMap is just a set of key-value pairs. It allow you to decouple configuration artifacts from image content.
. Secrets allows separating sensitive information such as credentials and keys from an application.

ConfigMap is similar to Secrets, but provides a means of working with strings that don’t contain sensitive information.

This section will explain how to use ConfigMap and Secrets. Make sure you change to that directory before giving any commands in this chapter.

== Prerequisites

This chapter uses a cluster with 3 master nodes and 5 worker nodes as described here: link:../cluster-install#multi-master-multi-node-multi-az-gossip-based-cluster[multi-master, multi-node gossip based cluster].

All configuration files for this chapter are in the `config-secrets` directory.

== ConfigMap

This section will explain:

. Pass configuration information to a Pod
. Define environment variables in a Pod using ConfigMap

=== Create a ConfigMap object

Create a ConfigMap:

    $ kubectl apply -f ./templates/redis-configmap.yaml
    configmap "redis-config" created

`redis-configmap.yaml` is a standard resource configuration file. It defines the configuration information as:

    data:
      redis-config: |
        maxmemory=2mb
        maxmemory-policy=allkeys-lru

The configuration data is stored in the main key `data`. `redis-config` is an attribute inside this key where the configuration information for the Redis pod is defined as key-value pairs.

Get the list of ConfigMaps:

    $ kubectl get configmap
    NAME           DATA      AGE
    redis-config   1         14s

Get more details about the created ConfigMap:

```
$ kubectl get configmap/redis-config -o yaml
apiVersion: v1
items:
- apiVersion: v1
  data:
    redis-config: |
      maxmemory 2mb
      maxmemory-policy allkeys-lru
  kind: ConfigMap
  metadata:
    creationTimestamp: 2017-10-22T18:38:27Z
    labels:
      k8s-app: redis
    name: redis-config
    namespace: default
    resourceVersion: "302238"
    selfLink: /api/v1/namespaces/default/configmaps/redis-config
    uid: 316309d0-b758-11e7-8c3f-06329c8974cc
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
```

The configuration information is shown as key/value pairs in the `data` key.

==== Alternative ways to create ConfigMap

We created a ConfigMap using a resource configuration file. Other ways to create ConfigMap are listed below:

NOTE: These ConfigMaps are using the exact same name as the one previously created. If you like to try the commands, then you either need to give a different name to the ConfigMap or delete the previously created ConfigMap using the command `kubectl delete -f ./templates/redis-configmap.yaml`.

. `kubectl create configmap --from-literal=<key>:<value>`. Multiple `--from-literal=<key>:<value>` options can be used to define different key/value pairs. For example:

  $ kubectl create configmap redis-config --from-literal=maxmemory=2mb --from-literal=maxmemory-policy=allkeys-lru
  configmap "redis-config" created
+
More details about the ConfigMap can be obtained as:
+
  $ kubectl get configmap/redis-config -o yaml
  apiVersion: v1
  data:
    maxmemory: 2mb
    maxmemory-policy: allkeys-lru
  kind: ConfigMap
  metadata:
    creationTimestamp: 2017-10-22T15:29:31Z
    name: redis-config
    namespace: default
    resourceVersion: "287452"
    selfLink: /api/v1/namespaces/default/configmaps/redis-config
    uid: cccf20b7-b73d-11e7-8c3f-06329c8974cc
+
. `kubectl create configmap redis-config --from-file=<properties file>` where `<properties file>` is a property file with key/value pairs. For example, `templates/redis-config` looks like:
+
  maxmemory 2mb
  maxmemory-policy allkeys-lru
+
And now the ConfigMap can be created as:
+
  $ kubectl create configmap redis-config --from-file=templates/redis-config
  configmap "redis-config" created
+
More details about the ConfigMap can be obtained as:
+
  $ kubectl get configmap/redis-config -o yaml
  apiVersion: v1
  data:
    redis-config: |
      maxmemory=2mb
      maxmemory-policy=allkeys-lru
  kind: ConfigMap
  metadata:
    creationTimestamp: 2017-10-22T15:56:08Z
    name: redis-config
    namespace: default
    resourceVersion: "289533"
    selfLink: /api/v1/namespaces/default/configmaps/redis-config
    uid: 84901162-b741-11e7-8c3f-06329c8974cc
+
The filename becomes a key stored in the data section of the ConfigMap. The file contents become the key’s value.

At the end of this section, you'll have created a ConfigMap `redis-config`.

=== Consume in a pod volume

A ConfigMap must be created before referencing it in a Pod specification (unless you mark the ConfigMap as "`optional`"). If you reference a ConfigMap that doesn’t exist would , the Pod won’t start.

Let's use `redis-config` ConfigMap to create our `redis.conf` configuration file in the pod `redis-pod`. It maps the ConfigMap to the volume where the configuration resides:

    $ kubectl apply -f ./templates/redis-pod.yaml
    pod "redis-pod" created

Wait for the pod to run:

    $ kubectl get pods
    NAME        READY     STATUS    RESTARTS   AGE
    redis-pod   1/1       Running   0          12m

Check logs from the pod to verify that Redis has started:

  $ kubectl logs redis-pod
                  _._                                                  
             _.-``__ ''-._                                             
        _.-``    `.  `_.  ''-._           Redis 2.8.19 (00000000/0) 64 bit
    .-`` .-```.  ```\/    _.,_ ''-._                                   
   (    '      ,       .-`  | `,    )     Running in stand alone mode
   |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
   |    `-._   `._    /     _.-'    |     PID: 6
    `-._    `-._  `-./  _.-'    _.-'                                   
   |`-._`-._    `-.__.-'    _.-'_.-'|                                  
   |    `-._`-._        _.-'_.-'    |           http://redis.io        
    `-._    `-._`-.__.-'_.-'    _.-'                                   
   |`-._`-._    `-.__.-'    _.-'_.-'|                                  
   |    `-._`-._        _.-'_.-'    |                                  
    `-._    `-._`-.__.-'_.-'    _.-'                                   
        `-._    `-.__.-'    _.-'                                       
            `-._        _.-'                                           
                `-.__.-'                                               

  [6] 22 Oct 18:39:45.386 # Server started, Redis version 2.8.19
  [6] 22 Oct 18:39:45.386 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
  [6] 22 Oct 18:39:45.386 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
  [6] 22 Oct 18:39:45.386 * The server is now ready to accept connections on port 6379

Validate that your redis cluster picked up the appropriate configuration:

    $ kubectl exec redis-pod -it redis-cli
    127.0.0.1:6379> CONFIG GET maxmemory
    1) "maxmemory"
    2) "2097152"
    127.0.0.1:6379> CONFIG GET maxmemory-policy
    1) "maxmemory-policy"
    2) "allkeys-lru"
    127.0.0.1:6379> quit

You should see the same values that were specified in `./templates/redis-configmap.yaml` outputted in the above commands.

Now, changing the pod configuration would involve the following steps:

. Edit `redis-configmap.yaml`
. Update the ConfigMap using the command: `kubectl apply -f templates/redis-configmap.yaml`
. Wrap the pod in a Deployment
. Terminate the pod, Deployment will restart the pod and pick up new configuration

=== Consume as pod environment variables

The data from ConfigMap can be used to initialize environment variables in a pod. We'll use `arungupta/print-hello` image to print "`Hello World`" on the console. The number of times this message is printed is defined by an environment variable `COUNT`. This value of this variable is defined in the ConfigMap.

==== Create a pod and use ConfigMap

. Create a ConfigMap:

  $ kubectl create configmap hello-config --from-literal=COUNT=2
  configmap "hello-config" created

. Get more details about this ConfigMap:

  $ kubectl get configmap/hello-config -o yaml
  apiVersion: v1
  data:
    COUNT: "2"
  kind: ConfigMap
  metadata:
    creationTimestamp: 2017-10-26T21:40:10Z
    name: hello-config
    namespace: default
    resourceVersion: "92516"
    selfLink: /api/v1/namespaces/default/configmaps/hello-config
    uid: 3dacb22f-ba96-11e7-ab9c-123f969a2ce2

. Use this ConfigMap to create a pod:

  $ kubectl apply -f templates/app-pod.yaml
  pod "app-pod" created
+
The pod configuration file looks like:
+
  apiVersion: v1
  kind: Pod
  metadata:
    labels:
      name: app-pod
    name: app-pod
  spec:
    containers:
    - name: app
      image: arungupta/print-hello:latest
      env:
      - name: COUNT
        valueFrom:
          configMapKeyRef:
            name: hello-config
            key: COUNT
      ports:
      - containerPort: 8080

. Observe logs from the pod:

  $ kubectl logs -f app-pod
  npm info it worked if it ends with ok
  npm info using npm@3.10.10
  npm info using node@v6.11.4
  npm info lifecycle webapp@1.0.0~prestart: webapp@1.0.0
  npm info lifecycle webapp@1.0.0~start: webapp@1.0.0

  > webapp@1.0.0 start /usr/src/app
  > node server.js

  Running on http://0.0.0.0:8080

. In a new terminal, expose the pod as a Service:

  $ kubectl expose pod app-pod --port=80 --target-port=8080 --name=app
  service "app" exposed

. Start Kubernetes proxy:

  kubectl proxy

. In a new terminal, access the service as:

  $ curl http://localhost:8001/api/v1/proxy/namespaces/default/services/app/
  printed 2 times
+
The pod logs are refreshed as well:
+
  Hello world 0
  Hello world 1

==== Change the ConfigMap and verify pod logs

. Edit the ConfigMap:

  $ kubectl edit configmap/hello-config

. Change the value to `4`
. Terminate the pod:

  $ kubectl delete pod/app-pod
  pod "app-pod" deleted

. Run the pod again:

  kubectl create -f templates/app-pod.yaml
  pod "app-pod" created

. Access the service again:

  curl http://localhost:8001/api/v1/proxy/namespaces/default/services/app/
  printed 4 times

. Logs from the pod are refreshed:

  Hello world 0
  Hello world 1
  Hello world 2
  Hello world 3

== Secrets

In this section we will demonstrate how to place secrets into the Kubernetes cluster and then show multiple ways of retrieving those secretes from within a pod.

=== Create secrets

First encode the secrets you want to apply, for this example we will use the username `admin` and the password `password`

    echo -n "admin" | base64
    echo -n "password" | base64

Both of these values are already written in the file `./templates/secret.yaml`. The configuration looks like:

```
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
data:
  username: YWRtaW4=
  password: cGFzc3dvcmQ=
```

You can now insert this secret in the Kubernetes cluster with the following command:

  kubectl apply -f ./templates/secret.yaml

The list of created secrets can be seen as:

  $ kubectl get secrets
  NAME                  TYPE                                  DATA      AGE
  default-token-4cqsx   kubernetes.io/service-account-token   3         8h
  mysecret              Opaque                                2         6s

The values of the secret are displayed as `Opaque`.

Get more details about the secret:

  $ kubectl describe secrets/mysecret
  Name:         mysecret
  Namespace:    default
  Labels:       <none>
  Annotations:  <none>

  Type:  Opaque

  Data
  ====
  password:  8 bytes
  username:  5 bytes

Once again, the values of the secret are not shown.

=== Consume in a pod volume

Deploy the pod:

    kubectl apply -f ./templates/pod-secret-volume.yaml

The pod configuration file looks like:

    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-secret-volume
    spec:
      containers:
      - name: pod-secret-volume
        image: redis
        volumeMounts:
        - name: foo
          mountPath: "/etc/foo"
          readOnly: true
      volumes:
      - name: foo
        secret:
          secretName: mysecret

Open a shell to the pod to see the secrets:

    kubectl exec -it pod-secret-volume /bin/bash
    ls /etc/foo
    cat /etc/foo/username ; echo
    cat /etc/foo/password ; echo

The above commands should result in the plain text values, the decoding is done for you.

Delete the pod:

    kubectl delete -f ./templates/pod-secret-volume.yaml

=== Consume as pod environment variables

Deploy the pod:

    kubectl apply -f ./templates/pod-secret-env.yaml

The pod configuration file looks like:

    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-secret-env
    spec:
      containers:
      - name: pod-secret-env
        image: redis
        env:
          - name: SECRET_USERNAME
            valueFrom:
              secretKeyRef:
                name: mysecret
                key: username
          - name: SECRET_PASSWORD
            valueFrom:
              secretKeyRef:
                name: mysecret
                key: password
      restartPolicy: Never

Open a shell to the pod to see the secrets:

    kubectl exec -it pod-secret-env /bin/bash
    echo $SECRET_USERNAME
    echo $SECRET_PASSWORD

The above commands illustrate how to see the secret values via environment variables.


== Vault (Work in progress)

These instructions are inspured from https://github.com/briankassouf/vault-kubernetes-demo.

=== Configure EC2 instance

. Create an EC2 instance with Linux flavor. For example `m4.large` with `Amazon Linux`
.. Make sure to allow port `8200` as part of `Configure Security Group`
.. Configure security group to allow 8200 (not TLS by default, more config required for TLS)
.. SSH into the machine:
+
```
ssh -i ~/.ssh/arun-us-east1.pem ec2-user@ec2-54-237-223-40.compute-1.amazonaws.com
```

=== Start Vault Server

. In EC2 instance, download Vault server:
+
```
wget https://releases.hashicorp.com/vault/0.9.0/vault_0.9.0_linux_amd64.zip
```
+
. Unzip Vault: `unzip vault_0.9.0_linux_amd64.zip`
. Start Vault server:
+
```
[ec2-user@ip-172-31-26-180 ~]$ ./vault server -dev &
[ec2-user@ip-172-31-26-180 ~]$ ==> Vault server configuration:

                     Cgo: disabled
         Cluster Address: https://127.0.0.1:8201
              Listener 1: tcp (addr: "127.0.0.1:8200", cluster address: "127.0.0.1:8201", tls: "disabled")
               Log Level: info
                   Mlock: supported: true, enabled: false
        Redirect Address: http://127.0.0.1:8200
                 Storage: inmem
                 Version: Vault v0.9.0
             Version Sha: bdac1854478538052ba5b7ec9a9ec688d35a3335

==> WARNING: Dev mode is enabled!

In this mode, Vault is completely in-memory and unsealed.
Vault is configured to only have a single unseal key. The root
token has already been authenticated with the CLI, so you can
immediately begin using the Vault CLI.

The only step you need to take is to set the following
environment variables:

    export VAULT_ADDR='http://127.0.0.1:8200'

The unseal key and root token are reproduced below in case you
want to seal/unseal the Vault or play with authentication.

Unseal Key: j/CEsRu7VaxjUdHHGGFfXnahxqhdAfRC8JRAgfE/lkg=
Root Token: ffd97e6f-2c33-aadd-c3b9-4f5d24995962

==> Vault server started! Log data will stream in below:

2017/11/19 02:49:02.177255 [INFO ] core: security barrier not initialized
2017/11/19 02:49:02.177365 [INFO ] core: security barrier initialized: shares=1 threshold=1
2017/11/19 02:49:02.177502 [INFO ] core: post-unseal setup starting
2017/11/19 02:49:02.190191 [INFO ] core: loaded wrapping token key
2017/11/19 02:49:02.190201 [INFO ] core: successfully setup plugin catalog: plugin-directory=
2017/11/19 02:49:02.190916 [INFO ] core: successfully mounted backend: type=kv path=secret/
2017/11/19 02:49:02.190929 [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/
2017/11/19 02:49:02.191032 [INFO ] core: successfully mounted backend: type=system path=sys/
2017/11/19 02:49:02.191205 [INFO ] core: successfully mounted backend: type=identity path=identity/
2017/11/19 02:49:02.194695 [INFO ] expiration: restoring leases
2017/11/19 02:49:02.194858 [INFO ] rollback: starting rollback manager
2017/11/19 02:49:02.195159 [INFO ] identity: entities restored
2017/11/19 02:49:02.195177 [INFO ] identity: groups restored
2017/11/19 02:49:02.195192 [INFO ] core: post-unseal setup complete
2017/11/19 02:49:02.195202 [INFO ] expiration: lease restore complete
2017/11/19 02:49:02.195331 [INFO ] core: root token generated
2017/11/19 02:49:02.195335 [INFO ] core: pre-seal teardown starting
2017/11/19 02:49:02.195337 [INFO ] core: cluster listeners not running
2017/11/19 02:49:02.195343 [INFO ] rollback: stopping rollback manager
2017/11/19 02:49:02.195399 [INFO ] core: pre-seal teardown complete
2017/11/19 02:49:02.195459 [INFO ] core: vault is unsealed
2017/11/19 02:49:02.195474 [INFO ] core: post-unseal setup starting
2017/11/19 02:49:02.195519 [INFO ] core: loaded wrapping token key
2017/11/19 02:49:02.195522 [INFO ] core: successfully setup plugin catalog: plugin-directory=
2017/11/19 02:49:02.195677 [INFO ] core: successfully mounted backend: type=kv path=secret/
2017/11/19 02:49:02.195754 [INFO ] core: successfully mounted backend: type=system path=sys/
2017/11/19 02:49:02.195888 [INFO ] core: successfully mounted backend: type=identity path=identity/
2017/11/19 02:49:02.195899 [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/
2017/11/19 02:49:02.196454 [INFO ] expiration: restoring leases
2017/11/19 02:49:02.196517 [INFO ] rollback: starting rollback manager
2017/11/19 02:49:02.196603 [INFO ] identity: entities restored
2017/11/19 02:49:02.196613 [INFO ] identity: groups restored
2017/11/19 02:49:02.196625 [INFO ] core: post-unseal setup complete
2017/11/19 02:49:02.196668 [INFO ] expiration: lease restore complete
```
+
. Run the command to configure Vault CLI to identify the server:
+
```
export VAULT_ADDR='http://127.0.0.1:8200'
```
+
. Check status:
+
```
[ec2-user@ip-172-31-26-180 ~]$ ./vault status
Type: shamir
Sealed: false
Key Shares: 1
Key Threshold: 1
Unseal Progress: 0
Unseal Nonce: 
Version: 0.9.0
Cluster Name: vault-cluster-cfa115bc
Cluster ID: c3b28ced-0625-5825-e758-cc4a71f6ad08

High-Availability Enabled: false
```

=== Configure Kubernetes Service Account

. Create the service account to verify service account token during login:

  $ kubectl create -f templates/vault-reviewer.yaml
  serviceaccount "vault-reviewer" created

. Create the RBAC role that will be used by the service account to access the TokenReview API:

  $ kubectl apply -f templates/vault-reviewer-rbac.yaml 
  clusterrolebinding "role-tokenreview-binding" created

. Creat a service account that will be used to login to the auth backend:

  $ kubectl create -f templates/vault-auth.yaml
  serviceaccount "vault-auth" created

=== Configure the Kubernetes Auth backend

Service account token, Kubernetes API server address and the certificate used to access the API server are needed in order to configure the Kubernetes Auth backend. Let's get these values.

. On the local machine, read the service account token:

  kubectl get secret \
  $(kubectl get serviceaccount vault-reviewer -o jsonpath={.secrets[0].name}) \
  -o jsonpath={.data.token} | base64 -D -
  eyJ . . . reg

. Get the API server address:

  $ kubectl config view -o jsonpath='{.clusters[*].cluster.server}'
  https://api-example-cluster-k8s-l-1dt7vk-41321592.us-east-1.elb.amazonaws.com https://192.168.99.100:8443
+
This is the address of API servers currently configured. The first one is for the cluster created by Kops. Second one is for the minikube server, if its running. The first one is relevant for our case.
+
. Extract the certificate
.. Find the default secret token:

  $ kubectl get secrets | grep default
  default-token-kvjn9          kubernetes.io/service-account-token   3         4d

.. Use the default token name to extract the certificate:

  $ kubectl get secrets default-token-kvjn9 -o jsonpath="{.data['ca\.crt']}" | base64 -D > ~/.kube/kops.crt

.. Copy the certificate to EC2 instance where Vault is running:

  $ scp -i ~/.ssh/arun-us-east1.pem ~/.kube/kops.crt ec2-user@ec2-54-237-223-40.compute-1.amazonaws.com:~/kops.crt
kops.crt                                                                                    100% 1046    11.1KB/s   00:00   

. Now that all the required values are available, configure the Kubernetes auth backend
.. In the EC2 instance, mount the Kubernetes auth backend:

  [ec2-user@ip-172-31-26-180 ~]$ ./vault auth-enable kubernetes
  Successfully enabled 'kubernetes' at 'kubernetes'!

.. Configure the auth backend:

  vault write auth/kubernetes/config \
    token_reviewer_jwt=<service-account-token>  \
    kubernetes_host=<api-server> \
    kubernetes_ca_cert=~/kops.crt
+
For example, here is how our command will look like:

  ./vault write auth/kubernetes/config \
    token_reviewer_jwt=eyJ . . . reg  \
    kubernetes_host=https://api-example-cluster-k8s-l-1dt7vk-41321592.us-east-1.elb.amazonaws.com \
    kubernetes_ca_cert=~/kops.crt
  Success! Data written to: auth/kubernetes/config


